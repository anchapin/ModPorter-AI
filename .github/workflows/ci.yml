
name: CI - Integration Tests (Optimized)

on:
  push:
    branches: ['agent/verify-group-19976823897-1764991919368']

env:
  REGISTRY: ghcr.io
  CACHE_VERSION: v2
  PYTHON_VERSION: "3.11"

jobs:
  # Check if we need to run tests based on changed files
  changes:
    runs-on: ubuntu-latest
    outputs:
      backend: ${{ steps.changes.outputs.backend }}
      frontend: ${{ steps.changes.outputs.frontend }}
      ai-engine: ${{ steps.changes.outputs.ai-engine }}
      docker: ${{ steps.changes.outputs.docker }}
      dependencies: ${{ steps.changes.outputs.dependencies }}
    steps:
      - uses: actions/checkout@v4
#       - uses: dorny/paths-filter@v3
#         id: changes
#         with:
#           filters: |
#             backend:
#               - 'backend/**'
#               - 'backend/requirements*.txt'
#             frontend:
#               - 'frontend/**'
#               - 'frontend/package.json'
#               - 'frontend/pnpm-lock.yaml'
#             ai-engine:
#               - 'ai-engine/**'
#               - 'ai-engine/requirements*.txt'
#             docker:
#               - 'docker/**'
#               - '**/Dockerfile*'
#             dependencies:
#               - '**/requirements*.txt'
#               - '**/package.json'
#               - 'frontend/pnpm-lock.yaml'
      - name: Set changes manually
        id: changes
        run: |
          echo "backend=true" >> $GITHUB_OUTPUT
          echo "frontend=true" >> $GITHUB_OUTPUT
          echo "ai-engine=true" >> $GITHUB_OUTPUT
          echo "docker=true" >> $GITHUB_OUTPUT
          echo "dependencies=true" >> $GITHUB_OUTPUT

  # Pre-build base images if dependencies changed
  prepare-base-images:
    name: Prepare Base Images
    runs-on: ubuntu-latest
    needs: changes
    if: ${{ needs.changes.outputs.dependencies == 'true' }}
    permissions:
      contents: read
      packages: write
    outputs:
      python-image: ${{ steps.image-tags.outputs.python-image }}
      should-build: ${{ steps.check-cache.outputs.should-build }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Calculate dependency hash
        id: deps-hash
        run: |
          DEPS_HASH=$(cat ai-engine/requirements.txt ai-engine/requirements-dev.txt backend/requirements.txt requirements-test.txt | sha256sum | cut -d' ' -f1 | head -c16)
          echo "hash=$DEPS_HASH" >> $GITHUB_OUTPUT
          echo "Dependencies hash: $DEPS_HASH"

      - name: Set image tags
        id: image-tags
        run: |
          REPO_LOWER=$(echo '${{ github.repository }}' | tr '[:upper:]' '[:lower:]')
          PYTHON_IMAGE="${{ env.REGISTRY }}/${REPO_LOWER}/python-base:${{ steps.deps-hash.outputs.hash }}"
          echo "python-image=$PYTHON_IMAGE" >> $GITHUB_OUTPUT
          echo "Python base image: $PYTHON_IMAGE"

      - name: Check if base image exists
        id: check-cache
        run: |
          if docker buildx imagetools inspect "${{ steps.image-tags.outputs.python-image }}" > /dev/null 2>&1; then
            echo "should-build=false" >> $GITHUB_OUTPUT
            echo "âœ… Base image exists, using cached version"
          else
            echo "should-build=true" >> $GITHUB_OUTPUT
            echo "ðŸ—ï¸ Base image needs to be built"
          fi

      - name: Build and push Python base image
        if: steps.check-cache.outputs.should-build == 'true'
        uses: docker/build-push-action@v5
        with:
          context: .
          file: docker/base-images/Dockerfile.python-base
          push: true
          tags: ${{ steps.image-tags.outputs.python-image }}
          cache-from: type=gha,scope=python-base-${{ env.CACHE_VERSION }}
          cache-to: type=gha,mode=max,scope=python-base-${{ env.CACHE_VERSION }}
          platforms: linux/amd64

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [changes, prepare-base-images]
    if: ${{ needs.changes.outputs.backend == 'true' || needs.changes.outputs.ai-engine == 'true' || needs.changes.outputs.dependencies == 'true' }}
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        test-suite: ["integration", "backend", "ai-engine"]
        include:
          - test-suite: integration
            test-path: "ai-engine/tests/integration/test_basic_integration.py"
            container-name: "integration-test"
          - test-suite: backend
            test-path: "backend/tests/integration/"
            container-name: "backend-test"
          - test-suite: ai-engine
            test-path: "ai-engine/tests/integration/test_imports.py"
            container-name: "ai-engine-test"

    # Use Python base image if available, fallback to setup-python
    container:
      image: ${{ needs.prepare-base-images.outputs.should-build == 'false' && needs.prepare-base-images.outputs.python-image || '' }}
      options: --name test-container-${{ matrix.test-suite }} --user root

    services:
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 3
        ports:
          - 6380:6379
      postgres:
        image: pgvector/pgvector:pg15
        env:
          POSTGRES_DB: modporter
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: password
          POSTGRES_INITDB_ARGS: --encoding=UTF-8 --lc-collate=C --lc-ctype=C
        options: >-
          --health-cmd "pg_isready -U postgres -d modporter"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5434:5432

    steps:
      - name: Fix file permissions
        run: |
          # Fix potential file permission issues from previous runs
          if [ -f ".github/CACHING_STRATEGY.md" ]; then
            chmod +w .github/CACHING_STRATEGY.md || true
          fi
          # Clean up any problematic files
          find .github -type f -name "*.md" -exec chmod +w {} \; 2>/dev/null || true
        continue-on-error: true

      - name: Checkout code
        uses: actions/checkout@v4

      # Conditional Python setup - only if not using container
      - name: Set up Python 3.11 (fallback)
        if: ${{ needs.prepare-base-images.outputs.should-build == 'true' || needs.prepare-base-images.outputs.python-image == '' }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"
          cache-dependency-path: |
            ai-engine/requirements*.txt
            backend/requirements*.txt
            requirements-test.txt

      # Multi-level caching strategy
      - name: Cache Python packages (L1 - pip cache)
        if: ${{ needs.prepare-base-images.outputs.should-build == 'true' || needs.prepare-base-images.outputs.python-image == '' }}
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-${{ hashFiles('**/requirements*.txt', 'requirements-test.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-pip-

      - name: Cache Python packages (L2 - site-packages)
        if: ${{ needs.prepare-base-images.outputs.should-build == 'true' || needs.prepare-base-images.outputs.python-image == '' }}
        uses: actions/cache@v4
        with:
          path: |
            ~/.local/lib/python${{ env.PYTHON_VERSION }}/site-packages
            /usr/local/lib/python${{ env.PYTHON_VERSION }}/site-packages
          key: ${{ runner.os }}-site-packages-${{ env.CACHE_VERSION }}-${{ hashFiles('**/requirements*.txt', 'requirements-test.txt') }}
          restore-keys: |
            ${{ runner.os }}-site-packages-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-site-packages-

      - name: Cache test artifacts
        uses: actions/cache@v4
        with:
          path: |
            ai-engine/.pytest_cache
            backend/.pytest_cache
            .coverage*
            htmlcov/
          key: ${{ runner.os }}-test-cache-${{ env.CACHE_VERSION }}-${{ matrix.test-suite }}-${{ hashFiles('**/test_*.py', '**/*_test.py') }}
          restore-keys: |
            ${{ runner.os }}-test-cache-${{ env.CACHE_VERSION }}-${{ matrix.test-suite }}-
            ${{ runner.os }}-test-cache-${{ env.CACHE_VERSION }}-

      # Fast dependency installation (only if not using base image)
      - name: Install Python dependencies (fast)
        if: ${{ needs.prepare-base-images.outputs.should-build == 'true' || needs.prepare-base-images.outputs.python-image == '' }}
        run: |
          echo "âš¡ Installing Python dependencies with optimizations..."
          python -m pip install --upgrade --no-cache-dir pip setuptools wheel

          # Install common requirements first (likely cached)
          pip install --no-deps pytest pytest-asyncio pytest-cov pytest-timeout pytest-mock

          # Install requirements with parallel downloads
          pip install --upgrade --force-reinstall --no-cache-dir \
            -r requirements-test.txt

      - name: Install service dependencies (fast)
        if: ${{ needs.prepare-base-images.outputs.should-build == 'true' || needs.prepare-base-images.outputs.python-image == '' }}
        run: |
          echo "âš¡ Installing service-specific dependencies..."

          case "${{ matrix.test-suite }}" in
            "ai-engine"|"integration")
              echo "Installing AI Engine dependencies..."
              cd ai-engine
              pip install --no-deps -r requirements.txt
              pip install --no-deps -r requirements-dev.txt
              pip install --no-deps -e .
              ;;
            "backend")
              echo "Installing Backend dependencies..."
              cd backend
              pip install --no-deps -r requirements.txt
              pip install --no-deps -r requirements-dev.txt
              ;;
          esac

      # Install system dependencies for health checks
      - name: Install system dependencies
        run: |
          echo "ðŸ”§ Installing system dependencies..."
          # Fix potential apt lock issues
          if [ -f "/var/lib/apt/lists/lock" ]; then
            echo "ðŸ”§ Removing stale apt lock file..."
            rm -f /var/lib/apt/lists/lock /var/cache/apt/archives/lock /var/lib/dpkg/lock-frontend /var/lib/dpkg/lock
          fi

          # Ensure dpkg is in a consistent state
          dpkg --configure -a || true

          apt-get update -qq
          apt-get install -y -qq netcat-traditional netcat-openbsd curl docker.io docker.io

      # Install Ollama for AI model testing
      # Install Ollama for AI model testing
      - name: Install Ollama
        run: |
          echo "ðŸ¤– Installing Ollama with retry logic..."
          curl -fsSL https://ollama.com/install.sh | sh
          # Install and start Ollama service
          ollama serve &
          # Wait for Ollama to start
          sleep 15
          # Pull model with retry logic
          echo "ðŸ“¥ Pulling llama3.2 model with retry logic..."
          MAX_RETRIES=3
          RETRY_DELAY=30
          MODEL_PULLED=false
          for i in $(seq 1 $MAX_RETRIES); do
            echo "Attempt $i of $MAX_RETRIES to pull llama3.2..."
            # Use timeout and background process (20 minutes)
            timeout 1200 ollama pull llama3.2 &&
            {
              echo "âœ… Model pull successful!"
              MODEL_PULLED=true
              break
            } ||
            {
              echo "âŒ Model pull failed (attempt $i)"
              if [ $i -eq $MAX_RETRIES ]; then
                echo "ðŸš¨ All retry attempts failed"
                echo "âš ï¸ Continuing without llama3.2 model - tests will skip model-dependent features"
                break
              fi
              echo "â³ Waiting $RETRY_DELAY seconds before retry..."
              sleep $RETRY_DELAY
            }
          done
          # Verify installation
          echo "Final Ollama status:"
          ollama list || echo "âš ï¸ Cannot list models - model may not be available"
          # Set environment variable for tests
          if [ "$MODEL_PULLED" = "true" ]; then
            echo "MODEL_AVAILABLE=true" >> $GITHUB_ENV
          else
            echo "MODEL_AVAILABLE=false" >> $GITHUB_ENV
          fi
      - name: Verify Python environment
        run: |
          echo "ðŸ” Python environment verification..."
          python --version
          pip --version
          echo "Installed packages:"
          pip list | head -20
          echo "..."
          echo "Python path: $(which python)"
          echo "Pip cache dir: $(pip cache dir)"

      - name: Wait for services to be ready
        run: |
          echo "ðŸ” Checking service connectivity..."

          echo "Testing Redis connectivity..."
          # Inside containers, services are accessible by service name, not localhost
          if timeout 60 bash -c 'until nc -z redis 6379; do echo "Waiting for Redis..."; sleep 2; done'; then
            echo "âœ… Redis port is accessible"
            # Test actual Redis protocol using service name
            if timeout 10 bash -c 'echo -e "*1\r\n\$4\r\nPING\r\n" | nc redis 6379 | grep -q PONG'; then
              echo "âœ… Redis is responding correctly"
            else
              echo "âš ï¸ Redis port open but not responding to PING"
            fi
          else
            echo "âŒ Redis connection failed"
            echo "Container networking debug:"
            echo "Available services:"
            getent hosts redis || echo "Redis service not resolvable"
            getent hosts postgres || echo "Postgres service not resolvable"
            exit 1
          fi

          echo "Testing PostgreSQL connectivity..."
          # Inside containers, services are accessible by service name, not localhost
          if timeout 60 bash -c 'until nc -z postgres 5432; do echo "Waiting for PostgreSQL..."; sleep 2; done'; then
            echo "âœ… PostgreSQL is ready"
          else
            echo "âŒ PostgreSQL connection failed"
            echo "PostgreSQL service debug:"
            getent hosts postgres || echo "Postgres service not resolvable"
            exit 1
          fi

          echo "Testing Ollama availability..."
          # Make sure Ollama is running
          if ! pgrep -f "ollama serve" > /dev/null; then
            echo "Starting Ollama service..."
            ollama serve &
            sleep 15
          fi

          if timeout 30 bash -c 'until curl -f http://localhost:11434/api/tags >/dev/null 2>&1; do echo "Waiting for Ollama..."; sleep 2; done'; then
            echo "âœ… Ollama is ready"
            echo "Checking for llama3.2 model..."
            if curl -f http://localhost:11434/api/tags | grep -q "llama3.2"; then
              echo "âœ… llama3.2 model is available"
            else
              echo "âš ï¸ Warning: llama3.2 model may not be available - pulling now..."
              ollama pull llama3.2
            fi
          else
            echo "âŒ Ollama connection failed - continuing anyway"
          fi

          echo "ðŸŽ¯ All critical services are ready!"

      - name: Set up database
        run: |
          echo "Database setup will be handled by the tests themselves"
          # The integration tests should handle database initialization

      - name: Run matrix test suite
        run: |
          echo "ðŸ§ª Starting test suite: ${{ matrix.test-suite }}"
          echo "Current directory: $(pwd)"
          echo "Environment variables:"
          env | grep -E "(REDIS|DATABASE|PYTHON|OLLAMA)" || true

          case "${{ matrix.test-suite }}" in
            "integration")
              echo "Running integration tests..."
              cd ai-engine
              echo "Current directory: $(pwd)"
              echo "Test files available:"
              find tests/integration -name "*.py" | head -5 || echo "No integration test files found"

              echo "Running basic integration test..."
              timeout 1200s python -m pytest tests/integration/test_basic_integration.py -v --tb=short --junitxml=pytest-results-${{ matrix.test-suite }}.xml -s --no-header
              ;;
            "backend")
              echo "Running backend tests..."
              cd backend
              echo "Current directory: $(pwd)"
              echo "Test files available:"
              find tests -name "*.py" | head -5 || echo "No backend test files found"

              echo "Running backend integration tests (focused on requirements/installation issue)..."
              timeout 1200s python -m pytest tests/integration/ tests/test_health.py -k "requirements or install or pip" -v --tb=short --junitxml=pytest-results-${{ matrix.test-suite }}.xml -s --no-header || 
              timeout 1200s python -m pytest tests/integration/ tests/test_health.py -v --tb=short --junitxml=pytest-results-${{ matrix.test-suite }}.xml -s --no-header
              ;;
            "ai-engine")
              echo "Running ai-engine tests..."
              cd ai-engine
              echo "Current directory: $(pwd)"
              echo "Test files available:"
              find tests/integration -name "*.py" | head -5 || echo "No ai-engine test files found"

              echo "Running import tests..."
              timeout 1200s python -m pytest tests/integration/test_imports.py -v --tb=short --junitxml=pytest-results-${{ matrix.test-suite }}.xml -s --no-header
              ;;
          esac

          echo "âœ… Test suite completed: ${{ matrix.test-suite }}"
        env:
          REDIS_URL: redis://redis:6379
          DATABASE_URL: postgresql+asyncpg://postgres:password@postgres:5432/modporter
          PYTHONPATH: ${{ github.workspace }}/${{ startsWith(matrix.test-suite, 'ai-engine') && 'ai-engine' || 'backend' }}
          LOG_LEVEL: INFO
          # Z.AI Configuration (Primary LLM backend)
          USE_Z_AI: "${{ secrets.Z_AI_API_KEY != '' && 'true' || 'false' }}"
          Z_AI_API_KEY: "${{ secrets.Z_AI_API_KEY }}"
          Z_AI_MODEL: "${{ vars.Z_AI_MODEL || 'glm-4-plus' }}"
          Z_AI_BASE_URL: "${{ vars.Z_AI_BASE_URL || 'https://api.z.ai/v1' }}"
          Z_AI_MAX_RETRIES: "${{ vars.Z_AI_MAX_RETRIES || '3' }}"
          Z_AI_TIMEOUT: "${{ vars.Z_AI_TIMEOUT || '300' }}"
          Z_AI_TEMPERATURE: "${{ vars.Z_AI_TEMPERATURE || '0.1' }}"
          Z_AI_MAX_TOKENS: "${{ vars.Z_AI_MAX_TOKENS || '4000' }}"
          # Ollama Configuration (Fallback)
          USE_OLLAMA: "${{ secrets.Z_AI_API_KEY == '' && 'true' || 'false' }}"
          OLLAMA_MODEL: "llama3.2"
          OLLAMA_BASE_URL: "http://localhost:11434"
          TESTING: "true"

      # Cache management removed - not using Docker buildx cache

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.test-suite }}
          path: |
            ai-engine/pytest-results-*.xml
            backend/pytest-results-*.xml
          retention-days: 7

      - name: Report test status
        if: failure()
        run: |
          echo "âŒ Integration tests failed for ${{ matrix.test-suite }}!"
          echo "Check the test results artifact for detailed information."
          exit 1

  # Prepare Node.js base image for frontend
  prepare-node-base:
    name: Prepare Node Base Image
    runs-on: ubuntu-latest
    needs: changes
    if: ${{ needs.changes.outputs.frontend == 'true' || needs.changes.outputs.dependencies == 'true' }}
    permissions:
      contents: read
      packages: write
    outputs:
      node-image: ${{ steps.image-tags.outputs.node-image }}
      should-build: ${{ steps.check-cache.outputs.should-build }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Calculate Node dependencies hash
        id: deps-hash
        run: |
          NODE_HASH=$(sha256sum frontend/package-lock.json | cut -d' ' -f1 | head -c16)
          echo "hash=$NODE_HASH" >> $GITHUB_OUTPUT
          echo "Node dependencies hash: $NODE_HASH"

      - name: Set image tags
        id: image-tags
        run: |
          REPO_LOWER=$(echo '${{ github.repository }}' | tr '[:upper:]' '[:lower:]')
          NODE_IMAGE="${{ env.REGISTRY }}/${REPO_LOWER}/node-base:${{ steps.deps-hash.outputs.hash }}"
          echo "node-image=$NODE_IMAGE" >> $GITHUB_OUTPUT
          echo "Node base image: $NODE_IMAGE"

      - name: Check if Node base image exists
        id: check-cache
        run: |
          if docker buildx imagetools inspect "${{ steps.image-tags.outputs.node-image }}" > /dev/null 2>&1; then
            echo "should-build=false" >> $GITHUB_OUTPUT
            echo "âœ… Node base image exists, using cached version"
          else
            echo "should-build=true" >> $GITHUB_OUTPUT
            echo "ðŸ—ï¸ Node base image needs to be built"
          fi

  # Frontend tests run only when frontend code changes
  frontend-tests:
    name: Frontend Tests
    runs-on: ubuntu-latest
    needs: [changes, prepare-node-base]
    if: ${{ needs.changes.outputs.frontend == 'true' || needs.changes.outputs.dependencies == 'true' }}
    timeout-minutes: 10
    strategy:
      fail-fast: false
      matrix:
        test-type: ["unit", "build", "lint"]
        include:
          - test-type: unit
            cache-key: "test"
            upload-artifacts: true
          - test-type: build
            cache-key: "build"
            upload-artifacts: false
          - test-type: lint
            cache-key: "lint"
            upload-artifacts: false

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js 20
        uses: actions/setup-node@v4
        with:
          node-version: "20.19.0"

      # Multi-level caching for Node.js
      - name: Cache Node.js packages (L1 - npm cache)
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: ${{ runner.os }}-npm-cache-${{ env.CACHE_VERSION }}-${{ hashFiles('frontend/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-npm-cache-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-npm-cache-

      - name: Cache Node.js packages (L2 - node_modules)
        uses: actions/cache@v4
        with:
          path: |
            node_modules
            frontend/node_modules
            ~/.cache/Cypress
          key: ${{ runner.os }}-frontend-${{ env.CACHE_VERSION }}-${{ hashFiles('frontend/package-lock.json', 'pnpm-workspace.yaml') }}
          restore-keys: |
            ${{ runner.os }}-frontend-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-frontend-

      - name: Cache build artifacts
        if: matrix.test-type == 'build'
        uses: actions/cache@v4
        with:
          path: |
            frontend/dist
            frontend/.vite
            frontend/node_modules/.vite
          key: ${{ runner.os }}-frontend-build-${{ env.CACHE_VERSION }}-${{ hashFiles('frontend/src/**', 'frontend/index.html', 'frontend/vite.config.*') }}
          restore-keys: |
            ${{ runner.os }}-frontend-build-${{ env.CACHE_VERSION }}-

      - name: Install dependencies (optimized)
        run: |
          echo "âš¡ Installing frontend dependencies with optimizations..."
          cd frontend

          # Clear npm cache to avoid 'Cannot read properties of null' error
          npm cache clean --force

          # Remove platform-specific package-lock and regenerate for Linux
          rm -f package-lock.json

          # Use npm install with platform-specific filtering
          npm install --prefer-offline --no-audit --no-fund --force

          echo "âœ… Dependencies installed successfully"

      - name: Run optimized test
        run: |
          cd frontend
          echo "ðŸš€ Running ${{ matrix.test-type }} tests..."

          case "${{ matrix.test-type }}" in
            "unit")
              # Run tests with coverage in CI mode
              npm run test:ci
              ;;
            "build")
              # Build with production optimizations
              NODE_ENV=production npm run build
              echo "Build size analysis:"
              du -sh dist/* 2>/dev/null || echo "Build completed"
              ;;
            "lint")
              # Run linting
              npm run lint
              ;;
          esac

      - name: Upload frontend test results
        uses: actions/upload-artifact@v4
        if: always() && matrix.upload-artifacts == 'true'
        with:
          name: frontend-test-results-${{ matrix.test-type }}
          path: |
            frontend/coverage/
            frontend/test-results/
          retention-days: 7

      - name: Report test metrics
        if: always()
        run: |
          echo "ðŸ“Š Frontend Test Metrics - ${{ matrix.test-type }}"
          echo "============================================="
          case "${{ matrix.test-type }}" in
            "unit")
              if [ -f "frontend/coverage/coverage-summary.json" ]; then
                echo "Coverage report generated âœ…"
              fi
              ;;
            "build")
              if [ -d "frontend/dist" ]; then
                DIST_SIZE=$(du -sh frontend/dist | cut -f1)
                echo "Build size: $DIST_SIZE âœ…"
              fi
              ;;
            "lint")
              echo "Linting completed âœ…"
              ;;
          esac

  # Test coverage enforcement
  coverage-check:
    name: Test Coverage Check
    runs-on: ubuntu-latest
    needs: [changes, prepare-base-images]
    if: ${{ needs.changes.outputs.backend == 'true' || needs.changes.outputs.ai-engine == 'true' || needs.changes.outputs.dependencies == 'true' }}
    timeout-minutes: 15

    # Use Python base image if available, fallback to setup-python
    container:
      image: ${{ needs.prepare-base-images.outputs.should-build == 'false' && needs.prepare-base-images.outputs.python-image || '' }}
      options: --name coverage-test-container --user root

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      # Conditional Python setup - only if not using container
      - name: Set up Python 3.11 (fallback)
        if: ${{ needs.prepare-base-images.outputs.should-build == 'true' || needs.prepare-base-images.outputs.python-image == '' }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"
          cache-dependency-path: |
            ai-engine/requirements*.txt
            backend/requirements*.txt
            requirements-test.txt

      - name: Install system dependencies
        run: |
          echo "ðŸ”§ Installing system dependencies..."
          # Fix potential apt lock issues
          if [ -f "/var/lib/apt/lists/lock" ]; then
            echo "ðŸ”§ Removing stale apt lock file..."
            rm -f /var/lib/apt/lists/lock /var/cache/apt/archives/lock /var/lib/dpkg/lock-frontend /var/lib/dpkg/lock
          fi

          # Ensure dpkg is in a consistent state
          dpkg --configure -a || true

          apt-get update -qq
          apt-get install -y -qq bc

      - name: Install test dependencies
        run: |
          echo "âš¡ Installing test dependencies..."
          python -m pip install --upgrade --no-cache-dir pip setuptools wheel
          pip install --upgrade --force-reinstall --no-cache-dir \
            -r requirements-test.txt

      - name: Install backend dependencies
        run: |
          echo "ðŸ“¦ Installing backend dependencies..."
          cd backend
          pip install --no-deps -r requirements.txt
          pip install --no-deps -r requirements-dev.txt

      - name: Install ai-engine dependencies
        run: |
          echo "ðŸ¤– Installing ai-engine dependencies..."
          cd ai-engine
          pip install --no-deps -r requirements.txt
          pip install --no-deps -r requirements-dev.txt
          pip install --no-deps -e .

      - name: Run coverage tests for backend
        run: |
          echo "ðŸ§ª Running backend coverage tests..."
          cd backend
          python -m pytest src/tests/ tests/ \
            --cov=src \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term-missing \
            --cov-fail-under=45 \
            --tb=short \
            --strict-markers \
            --disable-warnings \
            --junitxml=backend-coverage-results.xml

      - name: Run coverage tests for ai-engine
        run: |
          echo "ðŸ¤– Running ai-engine coverage tests..."
          cd ai-engine
          python -m pytest tests/ \
            --cov=. \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term-missing \
            --cov-fail-under=34 \
            --tb=short \
            --strict-markers \
            --disable-warnings \
            --junitxml=ai-engine-coverage-results.xml

      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-reports
          path: |
            backend/coverage.xml
            backend/htmlcov/
            backend/coverage.json
            ai-engine/coverage.xml
            ai-engine/htmlcov/
            ai-engine/coverage.json
          retention-days: 7

      - name: Check coverage thresholds
        run: |
          echo "ðŸ“Š Verifying 80% coverage requirement..."

          # Check backend coverage
          if [ -f "backend/coverage.xml" ]; then
            BACKEND_COVERAGE=$(python -c "
            import xml.etree.ElementTree as ET
            tree = ET.parse('backend/coverage.xml')
            root = tree.getroot()
            coverage = root.find('.//coverage').get('line-rate')
            print(f'{float(coverage)*100:.1f}')
            ")
            echo "Backend coverage: ${BACKEND_COVERAGE}%"

            if (( $(echo "${BACKEND_COVERAGE} < 45" | bc -l) )); then
              echo "âŒ Backend coverage ${BACKEND_COVERAGE}% is below 45% threshold"
              echo "::error::Backend test coverage is ${BACKEND_COVERAGE}%, which is below the required 45%"
              exit 1
            else
              echo "âœ… Backend coverage ${BACKEND_COVERAGE}% meets 45% requirement"
            fi
          else
            echo "âš ï¸ Backend coverage report not found"
          fi

          # Check ai-engine coverage
          if [ -f "ai-engine/coverage.xml" ]; then
            AI_ENGINE_COVERAGE=$(python -c "
            import xml.etree.ElementTree as ET
            tree = ET.parse('ai-engine/coverage.xml')
            root = tree.getroot()
            coverage = root.find('.//coverage').get('line-rate')
            print(f'{float(coverage)*100:.1f}')
            ")
            echo "AI Engine coverage: ${AI_ENGINE_COVERAGE}%"

            if (( $(echo "${AI_ENGINE_COVERAGE} < 34" | bc -l) )); then
              echo "âŒ AI Engine coverage ${AI_ENGINE_COVERAGE}% is below 34% threshold"
              echo "::error::AI Engine test coverage is ${AI_ENGINE_COVERAGE}%, which is below required 34%"
              exit 1
            else
              echo "âœ… AI Engine coverage ${AI_ENGINE_COVERAGE}% meets 34% requirement"
            fi
          else
            echo "âš ï¸ AI Engine coverage report not found"
          fi

          echo "âœ… All coverage requirements met!"

      - name: Generate coverage summary
        if: always()
        run: |
          echo "## ðŸ“Š Test Coverage Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f "backend/coverage.xml" ]; then
            BACKEND_COVERAGE=$(python -c "
            import xml.etree.ElementTree as ET
            tree = ET.parse('backend/coverage.xml')
            root = tree.getroot()
            coverage = root.find('.//coverage').get('line-rate')
            print(f'{float(coverage)*100:.1f}')
            ")
            echo "| Component | Coverage | Status |" >> $GITHUB_STEP_SUMMARY
            echo "|-----------|----------|--------|" >> $GITHUB_STEP_SUMMARY
            if (( $(echo "${BACKEND_COVERAGE} >= 80" | bc -l) )); then
              echo "| Backend | ${BACKEND_COVERAGE}% | âœ… Pass |" >> $GITHUB_STEP_SUMMARY
            else
              echo "| Backend | ${BACKEND_COVERAGE}% | âŒ Fail |" >> $GITHUB_STEP_SUMMARY
            fi
          fi

          if [ -f "ai-engine/coverage.xml" ]; then
            AI_ENGINE_COVERAGE=$(python -c "
            import xml.etree