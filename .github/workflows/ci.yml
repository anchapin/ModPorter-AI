name: CI - Integration Tests

on:
  pull_request:
    branches: [ main, develop ]
  push:
    branches: [ main, develop ]

jobs:
  integration-tests:
    name: Integration Tests
    runs-on: [self-hosted, Linux, X64, ollama]
    timeout-minutes: 30

    services:
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

      postgres:
        image: pgvector/pgvector:pg15
        env:
          POSTGRES_DB: modporter
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: password
          POSTGRES_INITDB_ARGS: --encoding=UTF-8 --lc-collate=C --lc-ctype=C
        options: >-
          --health-cmd "pg_isready -U postgres -d modporter"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Cache Docker layers
      uses: actions/cache@v4
      with:
        path: /tmp/.buildx-cache
        key: ${{ runner.os }}-buildx-${{ github.sha }}
        restore-keys: |
          ${{ runner.os }}-buildx-

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      with:
        cache-from: type=local,src=/tmp/.buildx-cache
        cache-to: type=local,dest=/tmp/.buildx-cache-new,mode=max

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y curl postgresql-client redis-tools

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-test.txt

    - name: Install AI Engine dependencies
      run: |
        cd ai-engine
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
        pip install -e .

    - name: Install Backend dependencies
      run: |
        cd backend
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: Wait for services to be ready
      run: |
        echo "Waiting for Redis..."
        timeout 30 bash -c 'until redis-cli -h localhost -p 6379 ping; do sleep 1; done'
        echo "Waiting for PostgreSQL..."
        timeout 30 bash -c 'until pg_isready -h localhost -p 5432 -U postgres; do sleep 1; done'
        echo "Checking Ollama availability..."
        timeout 30 bash -c 'until curl -f http://localhost:11434/api/tags >/dev/null 2>&1; do echo "Waiting for Ollama..."; sleep 2; done'
        echo "Ensuring llama3.2 model is available..."
        curl -f http://localhost:11434/api/tags | grep -q "llama3.2" || echo "Warning: llama3.2 model may not be available"

    - name: Set up database
      run: |
        PGPASSWORD=password psql -h localhost -p 5432 -U postgres -d modporter -f backend/sql/init.sql || true
      env:
        POSTGRES_PASSWORD: password

    - name: Run integration tests
      run: |
        cd ai-engine
        python -m pytest src/tests/integration/test_end_to_end_integration.py -v --tb=short
      env:
        REDIS_URL: redis://localhost:6379
        DATABASE_URL: postgresql+asyncpg://postgres:password@localhost:5432/modporter
        PYTHONPATH: /home/runner/work/ModPorter-AI/ModPorter-AI/ai-engine
        LOG_LEVEL: INFO
        USE_OLLAMA: "true"
        OLLAMA_MODEL: "llama3.2"
        OLLAMA_BASE_URL: "http://localhost:11434"

    - name: Run full conversion workflow test
      run: |
        cd ai-engine
        python -m pytest src/tests/integration/test_full_conversion_workflow.py -v --tb=short
      env:
        REDIS_URL: redis://localhost:6379
        DATABASE_URL: postgresql+asyncpg://postgres:password@localhost:5432/modporter
        PYTHONPATH: /home/runner/work/ModPorter-AI/ModPorter-AI/ai-engine
        LOG_LEVEL: INFO
        USE_OLLAMA: "true"
        OLLAMA_MODEL: "llama3.2"
        OLLAMA_BASE_URL: "http://localhost:11434"

    - name: Run backend integration tests
      run: |
        cd backend
        python -m pytest src/tests/integration/ -v --tb=short
      env:
        REDIS_URL: redis://localhost:6379
        DATABASE_URL: postgresql+asyncpg://postgres:password@localhost:5432/modporter
        PYTHONPATH: /home/runner/work/ModPorter-AI/ModPorter-AI/backend
        LOG_LEVEL: INFO
        USE_OLLAMA: "true"
        OLLAMA_MODEL: "llama3.2"
        OLLAMA_BASE_URL: "http://localhost:11434"

    - name: Move cache
      run: |
        rm -rf /tmp/.buildx-cache
        mv /tmp/.buildx-cache-new /tmp/.buildx-cache || true

    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results
        path: |
          ai-engine/src/pytest-results.xml
          backend/src/pytest-results.xml
        retention-days: 7

    - name: Report test status
      if: failure()
      run: |
        echo "‚ùå Integration tests failed!"
        echo "Check the test results artifact for detailed information."
        exit 1