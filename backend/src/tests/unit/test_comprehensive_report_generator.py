"""
Comprehensive tests for the enhanced report generation system.
Tests implementation of Issue #10 - Conversion Report Generation System
"""

import pytest
import datetime
from typing import Dict, Any
from unittest.mock import Mock, patch

import sys
import importlib.util
from pathlib import Path

# Get the src directory and load modules directly
src_dir = Path(__file__).parent.parent.parent
sys.path.insert(0, str(src_dir))

# Load report_types module directly to avoid conflict with built-in types
spec = importlib.util.spec_from_file_location("report_types", src_dir / "types" / "report_types.py")
report_types = importlib.util.module_from_spec(spec)
spec.loader.exec_module(report_types)

# Import from the loaded module
InteractiveReport = report_types.InteractiveReport
SummaryReport = report_types.SummaryReport
FeatureAnalysis = report_types.FeatureAnalysis
FeatureAnalysisItem = report_types.FeatureAnalysisItem
AssumptionsReport = report_types.AssumptionsReport
AssumptionReportItem = report_types.AssumptionReportItem
DeveloperLog = report_types.DeveloperLog
ReportMetadata = report_types.ReportMetadata
ConversionStatus = report_types.ConversionStatus
ImpactLevel = report_types.ImpactLevel
create_report_metadata = report_types.create_report_metadata
calculate_quality_score = report_types.calculate_quality_score

from services.comprehensive_report_generator import ConversionReportGenerator


@pytest.fixture
def sample_conversion_result():
    """Sample conversion result data for testing."""
    return {
        "job_id": "test_job_123",
        "status": "completed",
        "overall_success_rate": 85.5,
        "total_features": 20,
        "converted_features": 17,
        "partially_converted_features": 2,
        "failed_features": 1,
        "assumptions_applied_count": 5,
        "processing_time_seconds": 45.2,
        "download_url": "/api/download/test_job_123",
        "total_files_processed": 150,
        "output_size_mb": 12.5,
        "features_data": [
            {
                "feature_name": "CustomBlock",
                "original_type": "Block",
                "converted_type": "minecraft:block",
                "status": "Success",
                "compatibility_score": 95.0,
                "assumptions_used": ["block_assumption_1"],
                "impact_assessment": "Low impact conversion",
                "visual_comparison": {"before": "Java block", "after": "Bedrock block"},
                "technical_notes": "Direct translation possible"
            },
            {
                "feature_name": "EntityAI",
                "original_type": "AI Component",
                "converted_type": "behavior_component",
                "status": "Partial Success",
                "compatibility_score": 70.0,
                "assumptions_used": ["ai_assumption_1", "ai_assumption_2"],
                "impact_assessment": "Medium impact - behavior simplified",
                "technical_notes": "Complex AI logic simplified for Bedrock"
            }
        ],
        "assumptions_detail_data": [
            {
                "original_feature": "CustomBlock Materials",
                "assumption_type": "Material Mapping",
                "bedrock_equivalent": "minecraft:stone",
                "impact_level": "Low",
                "user_explanation": "Custom material mapped to closest Bedrock equivalent",
                "technical_details": "Material properties approximated",
                "confidence_score": 0.9,
                "alternatives_considered": ["minecraft:dirt", "minecraft:cobblestone"]
            },
            {
                "original_feature": "Entity AI Pathfinding",
                "assumption_type": "AI Simplification",
                "bedrock_equivalent": "basic_pathfinding",
                "impact_level": "Medium",
                "user_explanation": "Complex pathfinding simplified for compatibility",
                "technical_details": "Advanced algorithms replaced with basic navigation",
                "confidence_score": 0.7,
                "alternatives_considered": ["no_pathfinding", "custom_pathfinding"]
            }
        ],
        "developer_logs_data": {
            "code_translation_details": [
                {
                    "timestamp": "2023-01-01T12:00:00Z",
                    "level": "INFO",
                    "message": "Successfully translated CustomBlock.java",
                    "details": {"source": "CustomBlock.java", "target": "custom_block.json"}
                }
            ],
            "api_mapping_issues": [
                {
                    "timestamp": "2023-01-01T12:00:00Z",
                    "level": "WARNING",
                    "message": "Java API has no direct Bedrock equivalent",
                    "details": {"java_api": "getCustomProperty", "bedrock_equivalent": "none"}
                }
            ],
            "file_processing_log": [
                {
                    "timestamp": "2023-01-01T12:00:00Z",
                    "level": "INFO",
                    "message": "Processed texture file successfully",
                    "details": {"file": "block_texture.png", "status": "converted"}
                }
            ],
            "performance_metrics": {
                "total_time_seconds": 45.2,
                "memory_peak_mb": 128,
                "cpu_usage_avg_percentage": 30.5
            },
            "error_details": []
        }
    }


@pytest.fixture
def report_generator():
    """Report generator instance for testing."""
    return ConversionReportGenerator()


class TestReportMetadata:
    """Test report metadata functionality."""
    
    def test_create_report_metadata(self):
        """Test report metadata creation."""
        job_id = "test_job_123"
        metadata = create_report_metadata(job_id)
        
        assert metadata.job_id == job_id
        assert metadata.report_id.startswith("report_test_job_123_")
        assert metadata.version == "2.0.0"
        assert metadata.report_type == "comprehensive"
        assert isinstance(metadata.generation_timestamp, datetime.datetime)
    
    def test_create_report_metadata_with_custom_id(self):
        """Test report metadata creation with custom report ID."""
        job_id = "test_job_123"
        report_id = "custom_report_456"
        metadata = create_report_metadata(job_id, report_id)
        
        assert metadata.job_id == job_id
        assert metadata.report_id == report_id


class TestQualityScore:
    """Test quality score calculation."""
    
    def test_calculate_quality_score_perfect(self):
        """Test quality score calculation for perfect conversion."""
        summary = SummaryReport(
            overall_success_rate=100.0,
            total_features=10,
            converted_features=10,
            partially_converted_features=0,
            failed_features=0,
            assumptions_applied_count=0,
            processing_time_seconds=30.0
        )
        
        score = calculate_quality_score(summary)
        assert score == 100.0
    
    def test_calculate_quality_score_mixed(self):
        """Test quality score calculation for mixed results."""
        summary = SummaryReport(
            overall_success_rate=70.0,
            total_features=10,
            converted_features=7,
            partially_converted_features=2,
            failed_features=1,
            assumptions_applied_count=3,
            processing_time_seconds=45.0
        )
        
        score = calculate_quality_score(summary)
        assert 0 <= score <= 100
        assert score == 82.0  # (7*1.0 + 2*0.6 + 1*0.0)/10 * 100
    
    def test_calculate_quality_score_no_features(self):
        """Test quality score calculation with no features."""
        summary = SummaryReport(
            overall_success_rate=0.0,
            total_features=0,
            converted_features=0,
            partially_converted_features=0,
            failed_features=0,
            assumptions_applied_count=0,
            processing_time_seconds=10.0
        )
        
        score = calculate_quality_score(summary)
        assert score == 0.0


class TestSummaryReportGeneration:
    """Test summary report generation."""
    
    def test_generate_summary_report(self, report_generator, sample_conversion_result):
        """Test basic summary report generation."""
        summary = report_generator.generate_summary_report(sample_conversion_result)
        
        assert summary.overall_success_rate == 85.5
        assert summary.total_features == 20
        assert summary.converted_features == 17
        assert summary.partially_converted_features == 2
        assert summary.failed_features == 1
        assert summary.assumptions_applied_count == 5
        assert summary.processing_time_seconds == 45.2
        assert summary.download_url == "/api/download/test_job_123"
        assert summary.total_files_processed == 150
        assert summary.output_size_mb == 12.5
        
        # Check calculated fields
        assert summary.conversion_quality_score > 0
        assert isinstance(summary.recommended_actions, list)
        assert len(summary.recommended_actions) > 0
    
    def test_generate_recommended_actions_excellent(self, report_generator):
        """Test recommended actions for excellent conversion."""
        summary = SummaryReport(
            overall_success_rate=95.0,
            total_features=10,
            converted_features=9,
            partially_converted_features=1,
            failed_features=0,
            assumptions_applied_count=2,
            processing_time_seconds=30.0
        )
        
        actions = report_generator._generate_recommended_actions(summary)
        assert "Excellent conversion" in actions[0]
    
    def test_generate_recommended_actions_needs_work(self, report_generator):
        """Test recommended actions for poor conversion."""
        summary = SummaryReport(
            overall_success_rate=30.0,
            total_features=10,
            converted_features=3,
            partially_converted_features=2,
            failed_features=5,
            assumptions_applied_count=15,
            processing_time_seconds=600.0
        )
        
        actions = report_generator._generate_recommended_actions(summary)
        assert any("Low success rate" in action for action in actions)
        assert any("Many assumptions" in action for action in actions)
        assert any("failed features" in action for action in actions)
        assert any("optimization" in action for action in actions)


class TestFeatureAnalysisGeneration:
    """Test feature analysis generation."""
    
    def test_generate_feature_analysis(self, report_generator, sample_conversion_result):
        """Test basic feature analysis generation."""
        analysis = report_generator.generate_feature_analysis(
            sample_conversion_result["features_data"]
        )
        
        assert len(analysis.features) == 2
        assert analysis.total_compatibility_score > 0
        assert isinstance(analysis.feature_categories, dict)
        assert isinstance(analysis.conversion_patterns, list)
        
        # Check first feature
        feature1 = analysis.features[0]
        assert feature1.name == "CustomBlock"
        assert feature1.original_type == "Block"
        assert feature1.converted_type == "minecraft:block"
        assert feature1.status == "Success"
        assert feature1.compatibility_score == 95.0
        
        # Check categorization
        assert "Blocks" in analysis.feature_categories
        assert "CustomBlock" in analysis.feature_categories["Blocks"]
    
    def test_calculate_compatibility_score(self, report_generator):
        """Test compatibility score calculation."""
        # Test successful feature
        feature_data = {
            "status": "Success",
            "assumptions_used": []
        }
        score = report_generator._calculate_compatibility_score(feature_data)
        assert score == 100.0
        
        # Test feature with assumptions
        feature_data = {
            "status": "Success",
            "assumptions_used": ["assumption1", "assumption2"]
        }
        score = report_generator._calculate_compatibility_score(feature_data)
        assert score == 90.0  # 100 - (2 * 5)
        
        # Test failed feature
        feature_data = {
            "status": "Failed",
            "assumptions_used": []
        }
        score = report_generator._calculate_compatibility_score(feature_data)
        assert score == 0.0
    
    def test_categorize_feature(self, report_generator):
        """Test feature categorization."""
        # Test block feature
        feature_data = {"feature_name": "CustomBlock", "original_type": "Block"}
        category = report_generator._categorize_feature(feature_data)
        assert category == "Blocks"
        
        # Test item feature
        feature_data = {"feature_name": "MagicSword", "original_type": "Item"}
        category = report_generator._categorize_feature(feature_data)
        assert category == "Items"
        
        # Test unknown feature
        feature_data = {"feature_name": "Mystery", "original_type": "Unknown"}
        category = report_generator._categorize_feature(feature_data)
        assert category == "Other"


class TestAssumptionsReportGeneration:
    """Test assumptions report generation."""
    
    def test_generate_assumptions_report(self, report_generator, sample_conversion_result):
        """Test basic assumptions report generation."""
        report = report_generator.generate_assumptions_report(
            sample_conversion_result["assumptions_detail_data"]
        )
        
        assert len(report.assumptions) == 2
        assert report.total_assumptions_count == 2
        assert report.impact_distribution["low"] == 1
        assert report.impact_distribution["medium"] == 1
        assert report.impact_distribution["high"] == 0
        
        # Check first assumption
        assumption1 = report.assumptions[0]
        assert assumption1.original_feature == "CustomBlock Materials"
        assert assumption1.assumption_type == "Material Mapping"
        assert assumption1.impact_level == "Low"
        assert assumption1.confidence_score == 0.9
        
        # Check categorization
        assert "Material Mapping" in report.category_breakdown
        assert len(report.category_breakdown["Material Mapping"]) == 1


class TestDeveloperLogGeneration:
    """Test developer log generation."""
    
    def test_generate_developer_log(self, report_generator, sample_conversion_result):
        """Test basic developer log generation."""
        log = report_generator.generate_developer_log(
            sample_conversion_result["developer_logs_data"]
        )
        
        assert len(log.code_translation_details) == 1
        assert len(log.api_mapping_issues) == 1
        assert len(log.file_processing_log) == 1
        assert len(log.error_details) == 0
        assert isinstance(log.performance_metrics, dict)
        assert log.performance_metrics["total_time_seconds"] == 45.2
        
        # Check generated optimizations and technical debt
        assert isinstance(log.optimization_opportunities, list)
        assert isinstance(log.technical_debt_notes, list)
    
    def test_identify_optimizations(self, report_generator):
        """Test optimization identification."""
        log_data = {
            "performance_metrics": {
                "memory_peak_mb": 600,  # High memory usage
                "total_time_seconds": 400  # Long processing time
            },
            "api_mapping_issues": [
                {"issue": "mapping1"},
                {"issue": "mapping2"},
                {"issue": "mapping3"},
                {"issue": "mapping4"},
                {"issue": "mapping5"},
                {"issue": "mapping6"}  # Many API issues
            ]
        }
        
        optimizations = report_generator._identify_optimizations(log_data)
        
        assert any("memory optimization" in opt.lower() for opt in optimizations)
        assert any("parallelization" in opt.lower() for opt in optimizations)
        assert any("api mapping" in opt.lower() for opt in optimizations)


class TestInteractiveReportGeneration:
    """Test complete interactive report generation."""
    
    def test_create_interactive_report(self, report_generator, sample_conversion_result):
        """Test complete interactive report creation."""
        job_id = "test_job_123"
        report = report_generator.create_interactive_report(sample_conversion_result, job_id)
        
        # Check report structure
        assert isinstance(report, InteractiveReport)
        assert report.metadata.job_id == job_id
        assert report.metadata.report_type == "comprehensive"
        
        # Check all sections are present
        assert isinstance(report.summary, SummaryReport)
        assert isinstance(report.feature_analysis, FeatureAnalysis)
        assert isinstance(report.assumptions_report, AssumptionsReport)
        assert isinstance(report.developer_log, DeveloperLog)
        
        # Check navigation structure
        assert "sections" in report.navigation_structure
        assert "expandable" in report.navigation_structure
        assert report.navigation_structure["expandable"] == True
        
        # Check export formats
        assert "pdf" in report.export_formats
        assert "json" in report.export_formats
        assert "html" in report.export_formats
    
    def test_report_to_dict(self, report_generator, sample_conversion_result):
        """Test report dictionary conversion."""
        job_id = "test_job_123"
        report = report_generator.create_interactive_report(sample_conversion_result, job_id)
        
        report_dict = report.to_dict()
        
        # Check structure
        assert "metadata" in report_dict
        assert "summary" in report_dict
        assert "feature_analysis" in report_dict
        assert "assumptions_report" in report_dict
        assert "developer_log" in report_dict
        
        # Check metadata
        assert report_dict["metadata"]["job_id"] == job_id
        assert "generation_timestamp" in report_dict["metadata"]
        
        # Check summary
        assert report_dict["summary"]["overall_success_rate"] == 85.5
        assert "conversion_quality_score" in report_dict["summary"]
    
    def test_report_to_json(self, report_generator, sample_conversion_result):
        """Test report JSON serialization."""
        job_id = "test_job_123"
        report = report_generator.create_interactive_report(sample_conversion_result, job_id)
        
        json_str = report.to_json()
        
        assert isinstance(json_str, str)
        assert job_id in json_str
        assert "overall_success_rate" in json_str
        assert "feature_analysis" in json_str


class TestEdgeCases:
    """Test edge cases and error conditions."""
    
    def test_empty_conversion_result(self, report_generator):
        """Test handling of empty conversion result."""
        empty_result = {
            "job_id": "empty_job",
            "total_features": 0,
            "converted_features": 0,
            "features_data": [],
            "assumptions_detail_data": [],
            "developer_logs_data": {}
        }
        
        report = report_generator.create_interactive_report(empty_result, "empty_job")
        
        assert report.summary.total_features == 0
        assert len(report.feature_analysis.features) == 0
        assert len(report.assumptions_report.assumptions) == 0
    
    def test_missing_fields(self, report_generator):
        """Test handling of missing fields in conversion result."""
        minimal_result = {
            "job_id": "minimal_job"
        }
        
        # Should not raise exception
        report = report_generator.create_interactive_report(minimal_result, "minimal_job")
        
        assert report.summary.total_features == 0
        assert report.summary.overall_success_rate == 0.0
    
    def test_invalid_data_types(self, report_generator):
        """Test handling of invalid data types."""
        invalid_result = {
            "job_id": "invalid_job",
            "total_features": "not_a_number",  # Invalid type
            "features_data": "not_a_list",     # Invalid type
        }
        
        # Should handle gracefully
        try:
            report = report_generator.create_interactive_report(invalid_result, "invalid_job")
            # If no exception, check defaults were used
            assert report.summary.total_features == 0
        except (TypeError, ValueError):
            # Expected for some invalid types
            pass


# Integration test
class TestReportGenerationIntegration:
    """Integration tests for complete report generation workflow."""
    
    @patch('time.time')
    def test_full_workflow_integration(self, mock_time, report_generator, sample_conversion_result):
        """Test complete workflow from conversion result to interactive report."""
        mock_time.return_value = 1234567890
        
        job_id = "integration_test_job"
        
        # Generate complete report
        report = report_generator.create_interactive_report(sample_conversion_result, job_id)
        
        # Verify all components work together
        assert report.metadata.job_id == job_id
        assert report.summary.overall_success_rate == 85.5
        assert len(report.feature_analysis.features) == 2
        assert len(report.assumptions_report.assumptions) == 2
        assert report.developer_log.performance_metrics["total_time_seconds"] == 45.2
        
        # Test serialization works
        json_output = report.to_json()
        assert job_id in json_output
        
        # Test quality metrics
        assert report.summary.conversion_quality_score > 0
        assert len(report.summary.recommended_actions) > 0
        
        # Test categorization
        assert "Blocks" in report.feature_analysis.feature_categories
        assert "Material Mapping" in report.assumptions_report.category_breakdown